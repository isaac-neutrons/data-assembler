"""
Parquet parser for nexus-processor output files.

Reads and interprets parquet files generated by nexus-processor:
- metadata.parquet
- sample.parquet
- daslogs.parquet
"""

from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Optional

import pyarrow.parquet as pq


@dataclass
class MetadataRecord:
    """Parsed metadata from metadata.parquet."""

    instrument_id: str
    run_number: int
    run_id: str
    title: Optional[str] = None
    start_time: Optional[str] = None
    experiment_identifier: Optional[str] = None  # IPTS number
    source_path: Optional[str] = None


@dataclass
class SampleRecord:
    """Parsed sample info from sample.parquet."""

    instrument_id: str
    run_number: int
    run_id: str


@dataclass
class DASLogRecord:
    """Single DAS log entry from daslogs.parquet."""

    instrument_id: str
    run_number: int
    run_id: str
    log_name: str
    device_name: Optional[str] = None
    device_id: Optional[str] = None
    time: Optional[float] = None
    value: Optional[str] = None
    value_numeric: Optional[float] = None
    average_value: Optional[float] = None
    min_value: Optional[float] = None
    max_value: Optional[float] = None


@dataclass
class ParquetData:
    """
    Complete parsed data from nexus-processor parquet files.

    Contains all data extracted from a set of parquet files
    for a single run.
    """

    metadata: Optional[MetadataRecord] = None
    sample: Optional[SampleRecord] = None
    daslogs: dict[str, DASLogRecord] = field(default_factory=dict)

    @property
    def run_number(self) -> Optional[int]:
        """Get run number from metadata."""
        if self.metadata:
            return self.metadata.run_number
        return None

    @property
    def instrument_id(self) -> Optional[str]:
        """Get instrument ID from metadata."""
        if self.metadata:
            return self.metadata.instrument_id
        return None

    @property
    def experiment_identifier(self) -> Optional[str]:
        """Get experiment identifier (IPTS) from metadata."""
        if self.metadata:
            return self.metadata.experiment_identifier
        return None

    def get_daslog_summary(self, log_name: str) -> Optional[dict]:
        """
        Get summary statistics for a DAS log.

        Returns dict with average_value, min_value, max_value.
        """
        if log_name in self.daslogs:
            log = self.daslogs[log_name]
            return {
                "average_value": log.average_value,
                "min_value": log.min_value,
                "max_value": log.max_value,
            }
        return None
        return None


class ParquetParser:
    """
    Parser for nexus-processor parquet output files.

    Reads parquet files from a directory and assembles them
    into a ParquetData structure.

    Usage:
        parser = ParquetParser()
        data = parser.parse_directory("/path/to/parquet_output")

        # Or parse individual files
        metadata = parser.parse_metadata("/path/to/metadata.parquet")
    """

    def __init__(self):
        """Initialize the parser."""
        pass

    def parse_directory(
        self,
        directory: str | Path,
        run_number: Optional[int] = None,
    ) -> ParquetData:
        """
        Parse all parquet files in a directory.

        Args:
            directory: Path to directory containing parquet files
            run_number: Optional run number to filter by

        Returns:
            ParquetData with all parsed data
        """
        directory = Path(directory)

        if not directory.exists():
            raise FileNotFoundError(f"Directory not found: {directory}")

        result = ParquetData()

        # Find and parse each file type
        for parquet_file in directory.glob("*.parquet"):
            name = parquet_file.stem.lower()

            if "metadata" in name:
                result.metadata = self.parse_metadata(parquet_file, run_number)
            elif "sample" in name and "event" not in name:
                result.sample = self.parse_sample(parquet_file, run_number)
            elif "daslogs" in name:
                result.daslogs = self.parse_daslogs(parquet_file, run_number)

        return result

    def parse_metadata(
        self,
        file_path: str | Path,
        run_number: Optional[int] = None,
    ) -> Optional[MetadataRecord]:
        """
        Parse metadata.parquet file.

        Args:
            file_path: Path to metadata.parquet
            run_number: Optional run number to filter by

        Returns:
            MetadataRecord or None if not found
        """
        table = pq.read_table(file_path)
        df = table.to_pandas()

        if run_number is not None:
            df = df[df["run_number"] == run_number]

        if df.empty:
            return None

        row = df.iloc[0]

        return MetadataRecord(
            instrument_id=self._get_value(row, "instrument_id"),
            run_number=int(self._get_value(row, "run_number")),
            run_id=self._get_value(row, "run_id"),
            title=self._get_value(row, "title"),
            start_time=self._get_value(row, "start_time"),
            experiment_identifier=self._get_value(row, "experiment_identifier"),
            source_path=self._get_value(row, "source_path"),
        )

    def parse_sample(
        self,
        file_path: str | Path,
        run_number: Optional[int] = None,
    ) -> Optional[SampleRecord]:
        """Parse sample.parquet file."""
        table = pq.read_table(file_path)
        df = table.to_pandas()

        if run_number is not None:
            df = df[df["run_number"] == run_number]

        if df.empty:
            return None

        row = df.iloc[0]

        return SampleRecord(
            instrument_id=self._get_value(row, "instrument_id"),
            run_number=int(self._get_value(row, "run_number")),
            run_id=self._get_value(row, "run_id"),
        )

    def parse_daslogs(
        self,
        file_path: str | Path,
        run_number: Optional[int] = None,
    ) -> dict[str, DASLogRecord]:
        """
        Parse daslogs.parquet file.

        Returns a dictionary mapping log_name to the aggregated log record
        (uses the first record for each log_name, which contains averages).
        """
        table = pq.read_table(file_path)
        df = table.to_pandas()

        if run_number is not None:
            df = df[df["run_number"] == run_number]

        # Group by log_name and take first record (contains aggregates)
        daslogs = {}
        for log_name, group in df.groupby("log_name"):
            row = group.iloc[0]
            daslogs[log_name] = DASLogRecord(
                instrument_id=self._get_value(row, "instrument_id"),
                run_number=int(self._get_value(row, "run_number")),
                run_id=self._get_value(row, "run_id"),
                log_name=log_name,
                device_name=self._get_value(row, "device_name"),
                device_id=self._get_value(row, "device_id"),
                time=self._get_value(row, "time"),
                value=self._get_value(row, "value"),
                value_numeric=self._get_value(row, "value_numeric"),
                average_value=self._get_value(row, "average_value"),
                min_value=self._get_value(row, "min_value"),
                max_value=self._get_value(row, "max_value"),
            )

        return daslogs

    def _get_value(self, row: Any, column: str) -> Any:
        """Safely get a value from a DataFrame row."""
        if column not in row.index:
            return None
        value = row[column]
        # Handle pandas NA values
        if value is None or (hasattr(value, "__class__") and "NA" in str(type(value))):
            return None
        # Handle numpy types
        if hasattr(value, "item"):
            return value.item()
        return value

    def _get_dict_value(self, row: Any, column: str) -> Optional[dict]:
        """Safely get a dict value from a DataFrame row."""
        value = self._get_value(row, column)
        if value is None:
            return None
        if isinstance(value, dict):
            return value
        # Handle pyarrow map types
        if hasattr(value, "as_py"):
            return value.as_py()
        return None


def find_parquet_files(
    base_dir: str | Path,
    run_number: int,
    instrument_id: Optional[str] = None,
) -> Optional[Path]:
    """
    Find parquet output directory for a given run.

    Searches for directories containing parquet files that match
    the given run number.

    Args:
        base_dir: Base directory to search
        run_number: Run number to find
        instrument_id: Optional instrument ID to narrow search

    Returns:
        Path to directory containing parquet files, or None if not found
    """
    base_dir = Path(base_dir)

    # Common patterns for parquet output directories
    patterns = [
        f"*{run_number}*",
        f"*_{run_number}_*",
        f"{instrument_id}_{run_number}" if instrument_id else None,
    ]

    for pattern in patterns:
        if pattern is None:
            continue
        for match in base_dir.glob(pattern):
            if match.is_dir():
                # Check if it contains parquet files
                if list(match.glob("*.parquet")):
                    return match

    # Also check if base_dir itself contains the files
    parquet_files = list(base_dir.glob("*.parquet"))
    if parquet_files:
        # Check if any file matches the run number
        for pf in parquet_files:
            if str(run_number) in pf.stem:
                return base_dir

    return None
